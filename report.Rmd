---
title: \bf{Project B Report}
output:
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    latex_engine: xelatex
  html_document:
    mathjax: local
    self_contained: no
graphics: yes
header-includes:
  - \usepackage{graphicx}
  - \usepackage{caption}
  - \usepackage{subcaption}
---

\begin{section}{Summary}
The objective of this report is to model the Apple Stock return rate, defined as $ret.AAPL_i = \frac{AAPL_i - AAPL_{i-1}}{AAPL_{i-1}}$, based on key metrics such as volatility, $S\&P$ 500 Index, and etc. 

To model the return rate, our group has surveyed a wide range of models including an autoregressive model, linear models from automated model selection, as well as transformed linear models. 

From the autoregressive model, we noticed the heteroscedascity caused by autocorrelation, which led us to determine that directly modelling the stock price is not the most ideal way to model the return rate. We also found discrepancy between the adjusted R-Squared value and the residual plots in the backfitted model, which will be further discussed later in this report. Through our investigation, our group has concluded that there is no truly ideal linear model for the Apple Stock return rate. Nevertheless, we were able to identify the inadequate models and gain insights on why those models did not work.
\end{section}

\begin{section}{Model Selection}
The first model to be considered is the autoregressive model, which directly models the stock price of day $i$ using the price from day $i-1$ and has the following expression: $$ AAPL_i = \beta_0 + \beta_1 AAPL_{i-1}$$

The residual plot from the fitted model has a clearly heteroscedastic property, since the residuals take on a fan shape.

\begin{center}\includegraphics[width=90mm]{autoregressive_residual_vs_fitted.png}\end{center}

We tried to resolve the heteroscedascity issue by implementing a Weighted Least Squares autoregressive model but the results remained the same (see Appendix for full code and plot comparison). After some research, it turns out that this is an irreducible property of the autoregressive model because the data is serially correlated. We realized that we needed something better than directly modelling the price. Hence we decided to directly model the return which, to re-iterate, is defined as $ret.AAPL_i = \frac{AAPL_i - AAPL_{i-1}}{AAPL_{i-1}}$.

Correlation between the coefficients was also expected from the data. Since it is a time-series financial data set, we knew and verified that time is correlated to variables such as the Apple Stock Price and the $S \& P$ 500 Index. The detailed matrix can be found in the Appendix section. We decided that this wasn't too much of an issue since it is an inevitable part of any time-series data.

Moving on from the autoregressive model, we then considered automated model selecting using forward selection, backward elemination, and stepwise selection, from which we obtained the following models (full code in Appendix):


\textbf{Forward selection: } $Return = \beta_0 + \beta_1VIX + \beta_2AAPL2 + \beta_3AAPL + \beta_4SPGSCITR$

\textbf{Backward elimination: } $Return = \beta_0 + \beta_1AAPL + \beta_2VIX + \beta_3SPGSCITR + \beta_4AAPL2$

\textbf{Stepwise selection: } $Return = \beta_0 + \beta_1VIX + \beta_2AAPL2 + \beta_3AAPL + \beta_4SPGSCITR$


Interestingly, all selection methods returned the same model. Before we proceeded any further, we consulted with Prof. Zeng. After receiving helpful advice from the professor, we realized that since $Return$ is calculated as a function of $AAPL$ and $AAPL2$, the two variables cannot be included in the same model. We then adjusted the full model by excluding the variable $AAPL$, hence only keeping the previous-day price, and obtained the results below:


\textbf{Forward selection: } $ Return = \beta_0 + \beta_1VIX + \beta_2AAPL2 + \beta_3SPGSCITR + \beta_4EEM$

\textbf{Backward elimination: } $ Return = \beta_0 + \beta_1VIX + \beta_2AAPL2 + \beta_3SPGSCITR + \beta_4EEM$

\textbf{Stepwise selection: } $ Return = \beta_0 + \beta_1VIX + \beta_2AAPL2 + \beta_3SPGSCITR + \beta_4EEM$

We decided to further analyze this model in the model diagnostics section.

Additionally, we considered how the distribution of the independent variables could affect the model fit. Since both $VIX$ and $SPGSCITR$ had heavily skewed histograms, we decided to log-transform the variables to make the distributions resemble a normal curve and obtained the following model:
\textbf{Transformed model: } $ Return = \beta_0 + \beta_1(log(VIX)^{-2}) + \beta_2AAPL2 + \beta_3(log(SPGSCITR)) + \beta_4EEM$. This will be the second model to be discussed in the model diagnostics section.

\end{section}

\begin{section}{Model Diagnostics}

We first look into some diagnostic plots of the two models for the sake of residual analysis and outlier detection.

\begin{figure}[h]
\begin{subfigure}{.5\textwidth}
  \includegraphics[width=85mm]{diagnostics/arm_covar_residuals.png}
  \caption{Autoregressive Model}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \includegraphics[width=85mm]{diagnostics/fm_covar_residuals.png}
  \caption{Automated Model}
\end{subfigure}
\end{figure}

There is a strong linear trend in the partial residual plot of the autoregressive model, and no deviation from the straight line. We see this trend with the covariates of the automated model as well, with only the `EEM` covariate and the log-transformed `VIX` displaying a small amount of deviation from the straight line. Hence, the assumption of linearity is satisfied for both models.

\begin{figure}[h]
\begin{subfigure}{.5\textwidth}
  \includegraphics[width=85mm]{diagnostics/arm_model_plots.png}
  \caption{Autoregressive Model}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \includegraphics[width=85mm]{diagnostics/fm_model_plots.png}
  \caption{Automated Model}
\end{subfigure}
\end{figure}

The residuals of the autoregressive model are heterodastic as the plot of the residuals versus the fitted values has a fan-shaped pattern. In addition, the Q-Q plot of the residuals is heavy-tailed and exhibits curvature. In comparison, the plot of the residuals versus the fitted values of the automated model has more randomness than and lacks the fan-shaped pattern indicative of heterodasticity, and the Q-Q plot, while still being heavy-tailed, follows the linear trend more closely. Hence, the automated model produces errors that satisfy the assumption of constant error variance and that have non-normality that might be reasonably ignored, while the plots of the autoregressive model indicate that there are non-constant variances of the error and non-normality that we may be able to fix.


\begin{figure}[h]
\begin{subfigure}{.5\textwidth}
  \includegraphics[width=85mm]{diagnostics/arm_acf_residuals.png}
  \caption{Autoregressive Model}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \includegraphics[width=85mm]{diagnostics/fm_acf_residuals.png}
  \caption{Automated Model}
\end{subfigure}
\end{figure}

We then looked into the last assumption of linear regression models: independence of the errors. As the stock data was time-series data and contained serial correlation, a scatterplot matrix was ruled out as a useful tool for detecting correlation. We instead considered ACF plots of the residuals, in combination with the results of the Durbin-Watson test. As can be seen in the ACF plots above, both models have explained away the autocorrelation in the residuals very well, as almost all of the sample correlations are within the limits. The results of the Durbin-Watson test on the models (shown in the table below) confirms this: for both models, the $p$-value of the test is high enough to accept the null hypothesis that there is no autocorrelation between the residuals.


```{r echo=FALSE, message=FALSE}
library(lmtest)
market_origin <- read.csv("market_index_clean.csv")
first <- market_origin[1,]
market <- market_origin[2:3104,]
market$AAPL2 <- market_origin[,"AAPL"][1:3103]
market$Return <- (market$AAPL - market$AAPL2)/market$AAPL2

market$Date <- market_origin$Date[2:3104]
date <- market$Date
first <- date[1]
day <- c()
for(i in 1:length(date)) {
  diff = round(difftime(date[i], first))
  day = c(day, diff)
}
market$Date <- day

## Splitting the data into a training and test set (80/20)
n <- length(market[,1])
split <- round(0.8*n)
market_train <- market[1:split,]
market_test <- market[(split+1):n,]

market.tr <- market
market.tr$VIXtr <- log(market$VIX)^(-2)
market.tr$SPGSCITRtr <- log(market$SPGSCITR)
market.tr_train <- market.tr[1:split,]
market.tr_test <- market.tr[(split+1):n,]

auto_regressive_model <- lm(AAPL~AAPL2, data=market_train)
final_model <- lm(Return~VIXtr+AAPL2+SPGSCITRtr+EEM, data=market.tr_train)

fm_dwtest <- dwtest(final_model, alternative=c("two.sided"), 
                   data=market.tr_train)
arm_dwtest <- dwtest(auto_regressive_model, 
                    alternative=c("two.sided"), data=market_train)

arm_cd_limit = round(1/round(0.8*n), 6)
fm_cd_limit = round(4/round(0.8*n), 6)
```

```{r echo=FALSE, message=FALSE}
library(magrittr)
library(knitr)
library(kableExtra)
dwtest_dt <- data.frame(
  c(fm_dwtest$statistic, arm_dwtest$statistic),
  c(fm_dwtest$p.value, arm_dwtest$p.value)
)
rownames(dwtest_dt) = c('Autoregressive', 'Automated')
colnames(dwtest_dt) = c('Test Statistic', 'p-value')

kable(dwtest_dt, "latex") %>%
  kable_styling(full_width = F) %>%
  add_footnote(paste("alternative:",fm_dwtest$alternative), 
               notation = "symbol")
```

The next concern we addressed was potential outliers and high-leverage cases. In both Cook's Distance plots below, there are no concerning observations that have a distance greater than 1, but most observations have a Cook's Distance greater than $\frac{p}{n}$, which is 0.001612 and 0.000403 for the automated and the autoregressive model, respectively. However, we see in both Residuals versus Leverage plots that there are no cases that are influential to the regression results. All points are well enough within the Cook's distance lines that said lines do not appear on either plot.

\begin{figure}[h]
\begin{subfigure}{.5\textwidth}
  \includegraphics[width=85mm]{diagnostics/arm_leverage_plots.png}
  \caption{Autoregressive Model}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \includegraphics[width=85mm]{diagnostics/fm_leverage_plots.png}
  \caption{Automated Model}
\end{subfigure}
\end{figure}

```{r include=FALSE, message=FALSE, warning=FALSE, fig.show=FALSE}
library("lattice")
library("DAAG")
arm_cv = cv.lm(data=market_train, form.lm=auto_regressive_model,
               m=10, printit=F)
fm_cv = cv.lm(data=market.tr, form.lm=final_model,
              m=10, printit=F)

nrmse <- function(mse, ylim) {
  yrange = ylim[2] - ylim[1] 
  sqrt(mse)/yrange
}

arm_nrmse = nrmse(attr(arm_cv, "ms"), range(market_train$AAPL)) 
fm_nrmse = nrmse(attr(fm_cv, "ms"), range(market.tr$Return))
```

Once we had performed residual analysis and outlier detection, we performed cross validation for the two models to determine if they were overfitting. The $k$-fold cross validation method was used - with $k=10$ - and the $RMSE$ over the 10 folds was calculated. For the sake of comparison, since the models have different dependent variables and hence different scales, the $RMSE$ had to be normalized by dividing it by the range of the observed values. We denote this calculation as the $NRMSE$. 

The autoregressive model has an $NRMSE$ of `r arm_nrmse`, a value very close to 0, indicating that this model is a very good fit. While still being a well-fitted model, the automated model will generally produce less accurate predictions than the former model as it has a higher $NRMSE$ of `r fm_nrmse`.

We explored this claim by using the two models to predict responses for a test set of data, obtained by splitting the original dataset via an 80:20 split. The plots below are of the distributions of the error of prediction obtained from this test.

\begin{figure}[h]
  \centering
  \includegraphics[width=85mm]{diagnostics/prediction_histograms.png}
  \captionsetup{labelformat=empty}
  \caption{Prediction Error Histograms}
\end{figure}

The autoregressive model produces far more inaccurate results when predicting, with the value of the residual being as high as 6 in some cases. The autoselected model performs extremely well, producing a higher number of accurate predictions and a much smaller range of error.

Based on our aforementioned results, the final model we decided to choose was the automated model, i.e. $ Return = \beta_0 + \beta_1(log(VIX)^{-2}) + \beta_2AAPL2 + \beta_3(log(SPGSCITR)) + \beta_4EEM$. While both models are well-fitted with most of the linear regression assumptions satisified and no significant outliers, the residuals of the automated model are homodastic and are closer to normality than those of the autoregressive model. In addition, though the autoregressive model is less overfitted than the automated model (as measured by the $NRMSE$), it is not by a significant difference and the automated model tends to produces more accurate predictions. The paramters estimates and confidence interval of the final model are displayed below in the table below.

```{r echo=FALSE}
ci_df <- data.frame(round(confint(final_model), 4))
ci_df['Estimate'] <- unname(final_model$coef)
intervals = paste(ci_df[,1], ci_df[,2], sep=', ')
ci_df['Intervals'] = paste0('[', intervals , ']')
ci_df[,1:2] = NULL
kable(ci_df, "latex") %>%
  kable_styling(full_width = F)
```

\end{section}

\begin{section}{Discussion}
\end{section}

\newpage
\begin{section}{Appendix}
Below is a collection of R code used in this report.
\end{section}

### Pre-process the data
```{r eval=FALSE}
market_origin <- read.csv("market_index_clean.csv")
first <- market_origin[1,]
market <- market_origin[2:3104,]
market$AAPL2 <- market_origin[,"AAPL"][1:3103]
market$Return <- (market$AAPL - market$AAPL2)/market$AAPL2

market$Date <- market_origin$Date[2:3104]
date <- market$Date
first <- date[1]
day <- c()
for(i in 1:length(date)) {
  diff = round(difftime(date[i], first))
  day = c(day, diff)
}
market$Date <- day

## Splitting the data into a training and test set (80/20)
n <- length(market[,1])
split <- round(0.8*n)
market_train <- market[1:split,]
market_test <- market[(split+1):n,]
```

### Full Model
```{r eval=FALSE}
full_model <- lm(Return~., data = market)
summary(full_model)
```


### Null Model
```{r eval=FALSE}
null_model <- lm(Return~1, data = market)
summary(null_model)
```

### Autoregressive Model
```{r eval=FALSE}
autoregressive_model <- lm(AAPL~AAPL2, data = market_train)
plot(fitted(autoregressive_model),residuals(autoregressive_model), 
     main = "Residual vs. Fitted", xlab = "Fitted Values", ylab = "Residuals")
```

### WLS Autoregressive Model
```{r eval=FALSE}
wts <-1/(fitted(lm(abs(residuals(autoregressive_model))~fitted(autoregressive_model)))^2)
wls <- lm(market_train$AAPL~market$AAPL2, weights = wts)
par(mfrow=c(1,2))
plot(fitted(autoregressive_model), autoregressive_model$residuals, 
     main="unweighted", xlab = "fitted", ylab = "residuals")
plot(fitted(wls), wls$residuals, main="weighted", xlab = "fitted", ylab = "residuals")
```

There is no apparent difference between the weighted least squares and the un-weighted autoregressive models.

### Correlation Matrix
```{r eval=FALSE}
cor(market_train)
```

### Forward Selection
```{r eval=FALSE}
step(null_model, scope = list(upper=full_model), direction="forward")
summary(lm(formula = Return ~ VIX + AAPL2 + AAPL + SPGSCITR, data = market_train))
```

### Backward Elimination
```{r eval=FALSE}
step(full_model, scope = list(lower=null_model), direction="backward")
summary(lm(formula = Return ~ AAPL + VIX + SPGSCITR + AAPL2, data = market_train))
```

### Stepwise Selection
```{r eval=FALSE}
step(null_model, scope = list(upper=full_model), direction="both")
```


### Forward Selection without AAPL
```{r eval=FALSE}
full_model <- lm(Return~SPX+VIX+SPGSCITR+BNDGLB+EEM+AAPL2, data = market)
step(null_model, scope = list(upper=full_model), direction="forward")
```

### Backward Elimination without AAPL
```{r eval=FALSE}
step(full_model, scope = list(lower=null_model), direction="backward")
```

### Stepwise Selection without AAPL
```{r eval=FALSE}
step(null_model, scope = list(upper=full_model), direction="both")
```

### Log-transformed model from stepwise selection results
```{r eval=FALSE}
## note that the VIX needed to be raised to the -2, after the log transformation
##  in order to obtain a distribution close to the Gaussian curve
market.tr <- market
market.tr$VIXtr <- log(market$VIX)^(-2)
market.tr$SPGSCITRtr <- log(market$SPGSCITR)
market.tr_train <- market.tr[1:split,]
market.tr_test <- market.tr[(split+1):n,]

transformed_model <- lm(Return~VIXtr+AAPL2+SPGSCITRtr+EEM, data=market.tr_train)
summary(transformed_model)
```

### Function for plotting diagnostic tools
```{r eval=FALSE}
diagnostic_plots <- function(model) {
  p <- length(model$coef) - 1 # the number of covariates in the model
  nrows <- p%/%2
  savepar <- par(mfrow=c(1,1))
  if (nrows > 0) {
    savepar <- par(mfrow=c(nrows, 2))
  }
  
  # Partial Residual v.s. Covariates Plot
  savepar
  crPlots(model, ylab="Partial Residual", smooth=T,
          main='')
  title("Partial Residual Plots", 
        outer=T, line=-1)
  
  # Q-Q Plot and Residual v.s. Fitted Plot 
  par(mfrow=c(1,2))
  plot(model, which=c(1,2))
  title(paste("Model Diagnostics"),
        outer=T, line=-1)
  
  ## Leverage Plots
  par(mfrow=c(1,2))
  plot(model, which=c(4,5))
  title(paste("Leverage Plots"),
        outer=T, line=-1)
}

diagnostic_plots(autoregressive_model)
diagnostic_plots(transformed_model)
```

### ACF Plots for the Residuals
```{r eval=FALSE}
## Correlation calculations and plot
## Using ACF Plots instead of scatterplot matrix
png('arm_acf_residuals.png')
acf(resid(auto_regressive_model), main='', lag.max=10)
title("Autocorrelation Function of Residuals", 
      outer=T, line=-1)
dev.off()

## Using ACF Plots instead of scatterplot matrix
png('fm_acf_residuals.png')
acf(resid(final_model), main='', lag.max=10)
title("Autocorrelation Function of Residuals", 
      outer=T, line=-1)
dev.off()
```

### Durbin-Watson Test for autocorrelation
```{r eval=FALSE}
library(magrittr)
library(knitr)
library(kableExtra)

fm_dwtest <- dwtest(transformed_model, alternative=c("two.sided"), 
                   data=market.tr_train)
arm_dwtest <- dwtest(auto_regressive_model, 
                    alternative=c("two.sided"), data=market_train)

dwtest_dt <- data.frame(
  c(fm_dwtest$statistic, arm_dwtest$statistic),
  c(fm_dwtest$p.value, arm_dwtest$p.value)
)
rownames(dwtest_dt) = c('Autoregressive', 'Automated')
colnames(dwtest_dt) = c('Test Statistic', 'p-value')

kable(dwtest_dt, "latex") %>%
  kable_styling(full_width = F) %>%
  add_footnote(paste("alternative:",fm_dwtest$alternative), 
               notation = "symbol")
```

### Cross-validation and calculation of the Normalized RMSE
```{r eval=FALSE, message=FALSE, warning=FALSE, fig.show=FALSE}
library("lattice")
library("DAAG")
arm_cv = cv.lm(data=market_train, form.lm=auto_regressive_model,
               m=10, printit=F)
fm_cv = cv.lm(data=market.tr, form.lm=final_model,
              m=10, printit=F)

nrmse <- function(mse, ylim) {
  yrange = ylim[2] - ylim[1] 
  sqrt(mse)/yrange
}

arm_nrmse = nrmse(attr(arm_cv, "ms"), range(market_train$AAPL)) 
fm_nrmse = nrmse(attr(fm_cv, "ms"), range(market.tr$Return))
```

### Predicting the response on the test dataset
```{r eval=FALSE, fig.height=4, fig.width=8}
arm_preds = predict(autoregressive_model, market_test) 
fm_preds = predict(transformed_model, market.tr_test)
arm_test_resids = market_test[,'AAPL'] - arm_preds
fm_test_resids = market.tr_test[,'Return'] - fm_preds

## Plots of the residuals from prediction
par(mfrow=c(1,2))
hist(arm_test_resids, xlab='Residuals', cex=13,
     main="Autoregressive Model")
hist(fm_test_resids, xlab='Residuals',
     main="Autoselected Model")
```

### Parameter Estimates and CI of Final Model
```{r eval=FALSE}
ci_df <- data.frame(round(confint(transformed_model), 4))
ci_df['Estimate'] <- unname(transformed_model$coef)
intervals = paste(ci_df[,1], ci_df[,2], sep=', ')
ci_df['Intervals'] = paste0('[', intervals , ']')
ci_df[,1:2] = NULL
kable(ci_df, "latex") %>%
  kable_styling(full_width = F)
```